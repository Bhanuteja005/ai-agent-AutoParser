"""
Tests for generated bank statement parsers.

This module dynamically tests parsers generated by the agent.
Each test compares the parser output against the expected CSV ground truth.
"""

import importlib
import os
from pathlib import Path
from typing import Optional

import pandas as pd
import pytest


# Project root directory
PROJECT_ROOT = Path(__file__).parent.parent


def get_parser_module(bank_name: str):
    """
    Dynamically import a parser module for a given bank.
    
    Args:
        bank_name: Name of the bank (e.g., 'icici')
        
    Returns:
        Imported module
        
    Raises:
        ImportError: If parser module doesn't exist
    """
    module_name = f"custom_parsers.{bank_name}_parser"
    try:
        return importlib.import_module(module_name)
    except ImportError as e:
        raise ImportError(
            f"Parser module '{module_name}' not found. "
            f"Run 'python agent.py --target {bank_name}' first."
        ) from e


def load_expected_csv(bank_name: str) -> pd.DataFrame:
    """
    Load the expected CSV ground truth for a bank.
    
    Args:
        bank_name: Name of the bank
        
    Returns:
        DataFrame with expected data
        
    Raises:
        FileNotFoundError: If CSV file doesn't exist
    """
    csv_path = PROJECT_ROOT / "data" / bank_name / "result.csv"
    
    if not csv_path.exists():
        raise FileNotFoundError(f"Expected CSV not found: {csv_path}")
    
    return pd.read_csv(csv_path)


def get_sample_pdf_path(bank_name: str) -> Path:
    """
    Get the path to the sample PDF for a bank.
    
    Args:
        bank_name: Name of the bank
        
    Returns:
        Path to PDF file
        
    Raises:
        FileNotFoundError: If PDF doesn't exist
    """
    data_dir = PROJECT_ROOT / "data" / bank_name
    
    # Look for PDF files in the directory
    pdf_files = list(data_dir.glob("*.pdf"))
    
    if not pdf_files:
        raise FileNotFoundError(f"No PDF files found in {data_dir}")
    
    return pdf_files[0]


def compare_dataframes(expected: pd.DataFrame, actual: pd.DataFrame) -> tuple[bool, str]:
    """
    Compare two DataFrames and provide detailed mismatch information.
    
    Args:
        expected: Expected DataFrame
        actual: Actual DataFrame from parser
        
    Returns:
        Tuple of (is_equal, error_message)
    """
    # Check if DataFrames are equal
    if expected.equals(actual):
        return True, ""
    
    errors = []
    
    # Check shape
    if expected.shape != actual.shape:
        errors.append(
            f"Shape mismatch: expected {expected.shape}, got {actual.shape}"
        )
    
    # Check columns
    expected_cols = list(expected.columns)
    actual_cols = list(actual.columns)
    
    if expected_cols != actual_cols:
        errors.append(
            f"Column mismatch:\n  Expected: {expected_cols}\n  Got: {actual_cols}"
        )
    
    # Check dtypes (if columns match)
    if expected_cols == actual_cols:
        dtype_mismatches = []
        for col in expected_cols:
            if expected[col].dtype != actual[col].dtype:
                dtype_mismatches.append(
                    f"  {col}: expected {expected[col].dtype}, got {actual[col].dtype}"
                )
        if dtype_mismatches:
            errors.append("Data type mismatches:\n" + "\n".join(dtype_mismatches))
    
    # Check row count
    if len(expected) != len(actual):
        errors.append(
            f"Row count mismatch: expected {len(expected)}, got {len(actual)}"
        )
    
    # Sample value comparison (first 5 mismatched rows)
    if expected_cols == actual_cols and len(expected) == len(actual):
        mismatched_rows = []
        for idx in range(min(len(expected), len(actual))):
            exp_row = expected.iloc[idx]
            act_row = actual.iloc[idx]
            if not exp_row.equals(act_row):
                mismatched_rows.append(f"  Row {idx}:")
                for col in expected_cols:
                    if exp_row[col] != act_row[col]:
                        mismatched_rows.append(
                            f"    {col}: expected '{exp_row[col]}', got '{act_row[col]}'"
                        )
                if len(mismatched_rows) > 20:  # Limit output
                    mismatched_rows.append("  ... (more rows)")
                    break
        
        if mismatched_rows:
            errors.append("Value mismatches:\n" + "\n".join(mismatched_rows))
    
    return False, "\n".join(errors)


# ==================== TESTS ====================

def test_icici_parser():
    """Test the ICICI bank parser."""
    bank_name = "icici"
    
    # Import parser module
    parser_module = get_parser_module(bank_name)
    
    # Check that parse function exists
    assert hasattr(parser_module, "parse"), \
        f"Parser module must expose a 'parse' function"
    
    parse_func = parser_module.parse
    
    # Get paths
    pdf_path = get_sample_pdf_path(bank_name)
    expected_df = load_expected_csv(bank_name)
    
    # Parse PDF
    actual_df = parse_func(str(pdf_path))
    
    # Validate output type
    assert isinstance(actual_df, pd.DataFrame), \
        f"parse() must return a pandas DataFrame, got {type(actual_df)}"
    
    # Compare DataFrames
    is_equal, error_msg = compare_dataframes(expected_df, actual_df)
    
    assert is_equal, f"Parser output doesn't match expected CSV:\n{error_msg}"


def test_parser_signature():
    """Test that the parser has the correct function signature."""
    bank_name = "icici"
    
    try:
        parser_module = get_parser_module(bank_name)
    except ImportError:
        pytest.skip(f"Parser for {bank_name} not generated yet")
    
    parse_func = parser_module.parse
    
    # Check function signature
    import inspect
    sig = inspect.signature(parse_func)
    params = list(sig.parameters.keys())
    
    assert len(params) == 1, \
        f"parse() must take exactly 1 parameter, got {len(params)}: {params}"
    
    assert params[0] == "pdf_path", \
        f"parse() parameter must be named 'pdf_path', got '{params[0]}'"
    
    # Check return type annotation if present
    if sig.return_annotation != inspect.Signature.empty:
        # Should be pd.DataFrame or similar
        return_type_str = str(sig.return_annotation)
        assert "DataFrame" in return_type_str, \
            f"parse() should return pd.DataFrame, annotation: {return_type_str}"


def test_parser_handles_missing_file():
    """Test that parser handles missing file gracefully."""
    bank_name = "icici"
    
    try:
        parser_module = get_parser_module(bank_name)
    except ImportError:
        pytest.skip(f"Parser for {bank_name} not generated yet")
    
    parse_func = parser_module.parse
    
    # Try parsing a non-existent file - should return empty DataFrame
    result = parse_func("nonexistent_file.pdf")
    
    # Verify it returns an empty DataFrame with correct columns
    assert isinstance(result, pd.DataFrame), "Should return a DataFrame"
    assert len(result) == 0, "Should return empty DataFrame for missing file"
    assert list(result.columns) == ['Date', 'Description', 'Debit Amt', 'Credit Amt', 'Balance'], \
        "Empty DataFrame should have correct columns"


# ==================== HELPER FOR CLI ====================

def run_parser_test(bank_name: str) -> bool:
    """
    Run parser test programmatically (used by agent).
    
    Args:
        bank_name: Name of the bank to test
        
    Returns:
        True if test passed, False otherwise
    """
    try:
        # Import parser
        parser_module = get_parser_module(bank_name)
        parse_func = parser_module.parse
        
        # Get paths
        pdf_path = get_sample_pdf_path(bank_name)
        expected_df = load_expected_csv(bank_name)
        
        # Parse
        actual_df = parse_func(str(pdf_path))
        
        # Compare
        is_equal, error_msg = compare_dataframes(expected_df, actual_df)
        
        if not is_equal:
            print(f"Test failed:\n{error_msg}")
            return False
        
        print(f"Test passed for {bank_name}!")
        return True
        
    except Exception as e:
        print(f"Test failed with exception: {str(e)}")
        import traceback
        traceback.print_exc()
        return False
